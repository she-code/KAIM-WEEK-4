{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "toSiahO4w8Y2"
      },
      "outputs": [],
      "source": [
        "!rm -rf /content/*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0sNf9HhM13LO"
      },
      "outputs": [],
      "source": [
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForTokenClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorForTokenClassification\n",
        ")\n",
        "from datasets import Dataset, load_metric\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# Function to read CONLL file\n",
        "def read_conll_file(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        sentences = []\n",
        "        current_sentence = {\"tokens\": [], \"ner_tags\": []}\n",
        "\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "\n",
        "            if not line:  # Sentence boundary\n",
        "                if current_sentence[\"tokens\"]:\n",
        "                    sentences.append(current_sentence)\n",
        "                    current_sentence = {\"tokens\": [], \"ner_tags\": []}\n",
        "                continue\n",
        "\n",
        "            parts = line.split('\\t')\n",
        "            if len(parts) == 2:\n",
        "                token, tag = parts\n",
        "                current_sentence[\"tokens\"].append(token)\n",
        "                current_sentence[\"ner_tags\"].append(tag)\n",
        "\n",
        "    return sentences\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "TPmOIUtk2UAB",
        "outputId": "c0f12344-dc96-41cd-91dc-2def6859d523"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2fac6c45-76fa-4dca-861f-a7319642e73f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2fac6c45-76fa-4dca-861f-a7319642e73f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving amharic_ner_conll_labeled_output.conll to amharic_ner_conll_labeled_output.conll\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mctqu1rD2Vzk"
      },
      "outputs": [],
      "source": [
        "input_file = \"amharic_ner_conll_labeled_output.conll\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Fl5PHKS3JiN"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset, DatasetDict\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def load_and_split_conll(file_path, val_size=0.2, test_size=0.1):\n",
        "    # Read the single CONLL file\n",
        "    data = read_conll_file(file_path)\n",
        "\n",
        "    # Convert to pandas DataFrame for easy splitting\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # Split into train, validation, and test\n",
        "    train_df, temp_df = train_test_split(df, test_size=val_size + test_size, random_state=42)\n",
        "    val_df, test_df = train_test_split(temp_df, test_size=test_size/(val_size + test_size), random_state=42)\n",
        "\n",
        "    # Create DatasetDict\n",
        "    return DatasetDict({\n",
        "        \"train\": Dataset.from_pandas(train_df),\n",
        "        \"validation\": Dataset.from_pandas(val_df),\n",
        "        \"test\": Dataset.from_pandas(test_df)\n",
        "    })\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9NWzD1831tA"
      },
      "outputs": [],
      "source": [
        "MODELS_TO_COMPARE = [\n",
        "    \"xlm-roberta-base\",\n",
        "    \"distilbert-base-multilingual-cased\",\n",
        "    \"bert-base-multilingual-cased\"\n",
        "]\n",
        "\n",
        "def compare_models(dataset):\n",
        "    results = []\n",
        "\n",
        "    # Get label list\n",
        "    global label_list\n",
        "    all_tags = set()\n",
        "    for split in dataset.values():\n",
        "        for tags in split[\"ner_tags\"]:\n",
        "            all_tags.update(tags)\n",
        "    label_list = sorted(all_tags)\n",
        "\n",
        "    # Create label mappings\n",
        "    label2id = {label: i for i, label in enumerate(label_list)}\n",
        "    id2label = {i: label for i, label in enumerate(label_list)}\n",
        "\n",
        "    # Define MAX_LENGTH, LEARNING_RATE, BATCH_SIZE, NUM_EPOCHS, and device\n",
        "    # These variables were used in the original code but not defined.\n",
        "    # You should set appropriate values for these.\n",
        "    MAX_LENGTH = 128\n",
        "    LEARNING_RATE = 2e-5\n",
        "    BATCH_SIZE = 16\n",
        "    NUM_EPOCHS = 3\n",
        "\n",
        "    import torch\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "    # Define the compute_metrics function\n",
        "    # This function was used in the original code but not defined.\n",
        "    # install the 'seqeval' library to use the metric.\n",
        "    !pip install -q seqeval\n",
        "    from datasets import load_metric\n",
        "    metric = load_metric(\"seqeval\")\n",
        "\n",
        "    def compute_metrics(p, label_list):\n",
        "        predictions, labels = p\n",
        "        predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "        # Remove ignored index (special tokens)\n",
        "        true_predictions = [\n",
        "            [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "            for prediction, label in zip(predictions, labels)\n",
        "        ]\n",
        "        true_labels = [\n",
        "            [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
        "            for prediction, label in zip(predictions, labels)\n",
        "        ]\n",
        "\n",
        "        results = metric.compute(predictions=true_predictions, references=true_labels)\n",
        "        return {\n",
        "            \"precision\": results[\"overall_precision\"],\n",
        "            \"recall\": results[\"overall_recall\"],\n",
        "            \"f1\": results[\"overall_f1\"],\n",
        "            \"accuracy\": results[\"overall_accuracy\"],\n",
        "        }\n",
        "\n",
        "\n",
        "    for model_name in MODELS_TO_COMPARE: # Iterate only through model names\n",
        "        try:\n",
        "            print(f\"\\n{'='*50}\")\n",
        "            print(f\"Training {model_name}\")\n",
        "            print(f\"{'='*50}\")\n",
        "\n",
        "            # Load tokenizer - FORCE fast version\n",
        "            tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
        "\n",
        "            # Tokenize function with fast tokenizer\n",
        "            def tokenize_and_align_labels(examples):\n",
        "                tokenized_inputs = tokenizer(\n",
        "                    examples[\"tokens\"],\n",
        "                    truncation=True,\n",
        "                    is_split_into_words=True,\n",
        "                    max_length=MAX_LENGTH,\n",
        "                    padding=\"max_length\"\n",
        "                )\n",
        "\n",
        "                labels = []\n",
        "                for i, label_seq in enumerate(examples[\"ner_tags\"]):\n",
        "                    word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "                    previous_word_idx = None\n",
        "                    label_ids = []\n",
        "                    for word_idx in word_ids:\n",
        "                        if word_idx is None:\n",
        "                            label_ids.append(-100)\n",
        "                        elif word_idx != previous_word_idx:\n",
        "                            # Use .get with a default of -100 to handle potential missing tags\n",
        "                            label_ids.append(label2id.get(label_seq[word_idx], -100))\n",
        "                        else:\n",
        "                            label_ids.append(-100)\n",
        "                        previous_word_idx = word_idx\n",
        "                    labels.append(label_ids)\n",
        "\n",
        "                tokenized_inputs[\"labels\"] = labels\n",
        "                return tokenized_inputs\n",
        "\n",
        "            # Tokenize dataset\n",
        "            tokenized_datasets = dataset.map(\n",
        "                tokenize_and_align_labels,\n",
        "                batched=True,\n",
        "                remove_columns=dataset[\"train\"].column_names\n",
        "            )\n",
        "\n",
        "            # Load model - Use AutoModelForTokenClassification\n",
        "            model = AutoModelForTokenClassification.from_pretrained(\n",
        "                model_name,\n",
        "                num_labels=len(label_list),\n",
        "                id2label=id2label,\n",
        "                label2id=label2id\n",
        "            ).to(device)\n",
        "\n",
        "            # Training arguments\n",
        "            training_args = TrainingArguments(\n",
        "                output_dir=f\"./results_{model_name.replace('/', '-')}\",\n",
        "                eval_strategy=\"epoch\",\n",
        "                learning_rate=LEARNING_RATE,\n",
        "                per_device_train_batch_size=BATCH_SIZE,\n",
        "                per_device_eval_batch_size=BATCH_SIZE,\n",
        "                num_train_epochs=NUM_EPOCHS,\n",
        "                weight_decay=0.01,\n",
        "                save_total_limit=2,\n",
        "                save_strategy=\"epoch\",\n",
        "                load_best_model_at_end=True,\n",
        "                metric_for_best_model=\"f1\",\n",
        "                logging_dir=f\"./logs_{model_name.replace('/', '-')}\",\n",
        "                logging_steps=10,\n",
        "                report_to=\"none\"\n",
        "            )\n",
        "\n",
        "            # Trainer\n",
        "            trainer = Trainer(\n",
        "                model=model,\n",
        "                args=training_args,\n",
        "                train_dataset=tokenized_datasets[\"train\"],\n",
        "                eval_dataset=tokenized_datasets[\"validation\"],\n",
        "                tokenizer=tokenizer,\n",
        "                data_collator=DataCollatorForTokenClassification(tokenizer),\n",
        "                compute_metrics=lambda p: compute_metrics(p, label_list)\n",
        "            )\n",
        "\n",
        "            # Train\n",
        "            start_time = time.time()\n",
        "            trainer.train()\n",
        "            training_time = time.time() - start_time\n",
        "\n",
        "            # Evaluate\n",
        "            eval_results = trainer.evaluate()\n",
        "\n",
        "            results.append({\n",
        "                \"model_name\": model_name,\n",
        "                \"f1_score\": eval_results[\"eval_f1\"],\n",
        "                \"precision\": eval_results[\"eval_precision\"],\n",
        "                \"recall\": eval_results[\"eval_recall\"],\n",
        "                \"accuracy\": eval_results[\"eval_accuracy\"],\n",
        "                \"training_time\": training_time,\n",
        "                \"model_size\": sum(p.numel() for p in model.parameters())\n",
        "            })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error training {model_name}: {str(e)}\")\n",
        "            import traceback\n",
        "            traceback.print_exc() # Print the full traceback for debugging\n",
        "            continue\n",
        "\n",
        "    if not results:\n",
        "        raise ValueError(\"All models failed to train. Check error messages above.\")\n",
        "\n",
        "    # Find the best model based on F1 score\n",
        "    best_model_index = np.argmax([r[\"f1_score\"] for r in results])\n",
        "    best_model = results[best_model_index]\n",
        "    best_model_path = f\"./best_model_{best_model['model_name'].replace('/', '-')}\"\n",
        "\n",
        "    # Save the best model\n",
        "    trainer.model.save_pretrained(best_model_path)\n",
        "    tokenizer.save_pretrained(best_model_path)\n",
        "\n",
        "    return pd.DataFrame(results), best_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBJnVbEq4bXO",
        "outputId": "858e678b-7b0a-44c2-f1d2-44e340e84060"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['tokens', 'ner_tags', '__index_level_0__'],\n",
              "        num_rows: 6\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['tokens', 'ner_tags', '__index_level_0__'],\n",
              "        num_rows: 2\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['tokens', 'ner_tags', '__index_level_0__'],\n",
              "        num_rows: 2\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = load_and_split_conll(\"amharic_ner_conll_labeled_output.conll\", val_size=0.2, test_size=0.1)\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 617,
          "referenced_widgets": [
            "489987fd81f840899fef881fe41ef791",
            "935ec902e2fe438aa3ba88a5ad3ae93f",
            "8bff119429cd44aa9cf2a66927389865",
            "c9b8f030cf4e49cba5f6e13436836e28",
            "9ed405e357054df68ede0a5ab0644bbd",
            "5d8a2212d9ec4a3cadbbc6ea90fb29a4",
            "2bb61384fb3c430c82448ae9d9ecbed0",
            "24838e09e821480d8bd2eb8f2ef9bdd0",
            "6925c5f683a342e3baadec99c1be6976",
            "a87c1e7249bb44418392a8176942750a",
            "f9eeac8cb33c4315bc07aa4b9913bae1",
            "fffd872fd6f746fdb7e1c880d1c1750d",
            "53ecf12ff9db40dd89cabf2fcf7ecdc4",
            "71085a3c414a4aaa8eabd0cc1508eefb",
            "62cfc3ccfe2043fcaeee888df503ffdf",
            "c20edfca4e3147078190ffdbde5358fc",
            "02358d24f38742ca9a8bd1b4690fde99",
            "abfc0c68c35546a58e48c062019067c8",
            "aaf5d1f1327d431c88c4ca9667711d4c",
            "d427400442b44559854ad067526792c2",
            "1a345eb23fd44f1fbaf05def87e7fa7e",
            "5e9efa3af71a4355ab80b0c2564e566d",
            "285924c9d8ce4f7eb8087ab58f314209",
            "5314529e7d164e13a5ebd34d207713b0",
            "4a435505f1be434b81630dc598873ef9",
            "dab32f4732ff4f8e9d636dbe2bb5a9b9",
            "c915d0e0cb364bce8b142369e674ad0c",
            "7bf2726c11064379a50fe01eaafc2161",
            "139a267d68254d6da852f09ed419bfe6",
            "0023e524c155470b9072937262552d64",
            "1f251f078feb4a718666df2f5446431d",
            "b706fe19734841799dcbc7fb50f46981",
            "122f8d8c929147c290e26b8e127f6088",
            "24a7a6bb4c3346f0bad5792828b1444d",
            "76845f8e32324bb8bcefa001fa8f5e56",
            "1ab4fa8b49fe47e8b99d6e5f02847d06",
            "270a68edb3ba46248295df628d5eb077",
            "8fd3103404ba4d5abcf4e6e4197e28c1",
            "5aa370ef38dc449c8664e253a55e3a6d"
          ]
        },
        "id": "AQj4mvsP17b1",
        "outputId": "52d8de97-3d6f-41ca-a21e-d7d87caa93b6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-6-84008034.py:39: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = load_metric(\"seqeval\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Training xlm-roberta-base\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "489987fd81f840899fef881fe41ef791",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/6 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fffd872fd6f746fdb7e1c880d1c1750d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "285924c9d8ce4f7eb8087ab58f314209",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-6-84008034.py:136: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 08:20, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.853103</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>0.029412</td>\n",
              "      <td>0.040000</td>\n",
              "      <td>0.536000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.790051</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.608000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.755643</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.600000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1/1 : < :]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Training distilbert-base-multilingual-cased\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "24a7a6bb4c3346f0bad5792828b1444d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/6 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "76845f8e32324bb8bcefa001fa8f5e56",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ab4fa8b49fe47e8b99d6e5f02847d06",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-6-84008034.py:136: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 02:47, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.872117</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.025641</td>\n",
              "      <td>0.037037</td>\n",
              "      <td>0.469880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.685045</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.025641</td>\n",
              "      <td>0.040000</td>\n",
              "      <td>0.692771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.599197</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.025641</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.704819</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1/1 : < :]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Training bert-base-multilingual-cased\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "270a68edb3ba46248295df628d5eb077",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/6 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8fd3103404ba4d5abcf4e6e4197e28c1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5aa370ef38dc449c8664e253a55e3a6d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-6-84008034.py:136: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 04:04, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.344515</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.716867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.106431</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.716867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.054486</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.716867</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1/1 : < :]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best model: xlm-roberta-base\n",
            "                           model_name  f1_score  precision    recall  \\\n",
            "0                    xlm-roberta-base  0.090909   0.200000  0.058824   \n",
            "1  distilbert-base-multilingual-cased  0.041667   0.111111  0.025641   \n",
            "2        bert-base-multilingual-cased  0.000000   0.000000  0.000000   \n",
            "\n",
            "   accuracy  training_time  model_size  \n",
            "0  0.608000     527.227098   277459977  \n",
            "1  0.704819     180.017216   134741001  \n",
            "2  0.716867     263.752807   177269769  \n"
          ]
        }
      ],
      "source": [
        "\n",
        "comparison_results, best_model = compare_models(dataset)\n",
        "print(f\"Best model: {best_model['model_name']}\")\n",
        "print(comparison_results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlicgM4Y1wJk"
      },
      "source": [
        "1. Imports and Initial Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "wa1wlYka1sGb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
        "import numpy as np\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "import shap\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50HHkdFU1z8S"
      },
      "source": [
        "2. Model Loading and Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "t_IOQCP016b5"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load your saved best model\n",
        "model_path = \"./best_model_xlm-roberta-base\"\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_path)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "# Ensure model is in evaluation mode\n",
        "model.eval()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "label_list = list(model.config.id2label.values())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sultWfD22cr"
      },
      "source": [
        "SHAP Implementation Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "6r5r8_4Q2z5_"
      },
      "outputs": [],
      "source": [
        "\n",
        "# def shap_explanation(text, model, tokenizer):\n",
        "#     \"\"\"Explain model predictions using SHAP with space tokenization\"\"\"\n",
        "#     print(\"\\nGenerating SHAP explanation...\")\n",
        "\n",
        "\n",
        "def shap_explanation(text, model, tokenizer):\n",
        "    \"\"\"Simplified SHAP explanation for space-tokenized text\"\"\"\n",
        "    print(\"\\nGenerating SHAP-style explanation...\")\n",
        "\n",
        "    words = space_tokenizer(text)\n",
        "    num_words = len(words)\n",
        "\n",
        "    print(\"Feature importance by position:\")\n",
        "    print(\"{:15} {:10} {}\".format(\"Word\", \"Position\", \"Importance\"))\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    # Create a simple positional importance analysis\n",
        "    for i, word in enumerate(words):\n",
        "        # Create modified versions of the text\n",
        "        original_pred = predict_ner(text)[1][i]\n",
        "\n",
        "        # Create text with this word masked\n",
        "        masked_words = words.copy()\n",
        "        masked_words[i] = \"[MASK]\"\n",
        "        masked_text = \" \".join(masked_words)\n",
        "        masked_pred = predict_ner(masked_text)[1][i]\n",
        "\n",
        "        # Calculate importance as prediction change\n",
        "        importance = abs(original_pred - masked_pred)\n",
        "\n",
        "        print(\"{:15} {:10} {:.2f}\".format(\n",
        "            word,\n",
        "            i,\n",
        "            importance\n",
        "        ))\n",
        "\n",
        "    print(\"\\nKey:\")\n",
        "    print(\"Importance = How much prediction changes when word is masked\")\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lwF1N9y250C"
      },
      "source": [
        "2. LIME Implementation Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "cygeob4T26Aw"
      },
      "outputs": [],
      "source": [
        "\n",
        "def lime_explanation(text, model, tokenizer, target_label_idx):\n",
        "    \"\"\"Simplified LIME explanation for space-tokenized text\"\"\"\n",
        "    print(f\"\\nGenerating LIME-style explanation for {label_list[target_label_idx]}...\")\n",
        "\n",
        "    words = space_tokenizer(text)\n",
        "    num_words = len(words)\n",
        "\n",
        "    # Create neighborhood of examples by removing one word at a time\n",
        "    neighborhood = []\n",
        "    for i in range(num_words):\n",
        "        modified_words = words.copy()\n",
        "        modified_words[i] = \"[MASK]\"\n",
        "        neighborhood.append(\" \".join(modified_words))\n",
        "\n",
        "    # Get predictions for all examples\n",
        "    predictions = []\n",
        "    for example in [text] + neighborhood:\n",
        "        _, preds = predict_ner(example)\n",
        "        predictions.append(preds)\n",
        "\n",
        "    # Calculate importance for each position\n",
        "    importance_scores = []\n",
        "    original_preds = predictions[0]\n",
        "    for i in range(num_words):\n",
        "        # Focus on the target label's prediction at this position\n",
        "        original_score = (original_preds[i] == target_label_idx)\n",
        "        modified_score = (predictions[i+1][i] == target_label_idx)\n",
        "        importance = abs(original_score - modified_score)\n",
        "        importance_scores.append((words[i], i, importance))\n",
        "\n",
        "    # Sort by importance\n",
        "    importance_scores.sort(key=lambda x: x[2], reverse=True)\n",
        "\n",
        "    print(\"\\nTop influential words:\")\n",
        "    print(\"{:15} {:10} {}\".format(\"Word\", \"Position\", \"Influence\"))\n",
        "    print(\"-\" * 40)\n",
        "    for word, pos, imp in importance_scores[:min(5, num_words)]:\n",
        "        print(\"{:15} {:10} {:.2f}\".format(word, pos, imp))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUn9lfh019lx"
      },
      "source": [
        "3. Custom Tokenizer Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "JNRuetMR1-9o"
      },
      "outputs": [],
      "source": [
        "# Custom space-based tokenizer\n",
        "def space_tokenizer(text):\n",
        "    return text.split()\n",
        "\n",
        "# Wrapper to make compatible with transformers and SHAP\n",
        "class SpaceTokenizerWrapper:\n",
        "    def tokenize(self, text):\n",
        "        return space_tokenizer(text)\n",
        "\n",
        "    def convert_tokens_to_ids(self, tokens):\n",
        "        return [i for i in range(len(tokens))]\n",
        "\n",
        "    def convert_ids_to_tokens(self, ids):\n",
        "        return [f\"token_{i}\" for i in ids]\n",
        "\n",
        "    # Add a __call__ method for SHAP compatibility\n",
        "    def __call__(self, text, **kwargs):\n",
        "        # This method should return an object similar to a Hugging Face tokenizer output\n",
        "        # For the purpose of SHAP's Text masker, simply returning the list of words might suffice\n",
        "        # or a structure that mimics the tokenizer's output.\n",
        "        # Let's try returning a list of words for now, as that's what text.split() gives.\n",
        "        return space_tokenizer(text)\n",
        "\n",
        "\n",
        "space_tokenizer_wrapper = SpaceTokenizerWrapper()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2_Mxpqw2B4p"
      },
      "source": [
        "4. Label Definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "TEBkcsJt2DlE"
      },
      "outputs": [],
      "source": [
        "# Define NER label categories\n",
        "label_list = [\n",
        "    \"O\",\n",
        "    \"B-Product\", \"I-Product\",\n",
        "    \"B-PRICE\", \"I-PRICE\",\n",
        "    \"B-LOC\", \"I-LOC\",\n",
        "    \"B-CONTACT\", \"I-CONTACT\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-Oq6S2l2F7H"
      },
      "source": [
        "5. Core Prediction Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "-zPXlSn62Hsh"
      },
      "outputs": [],
      "source": [
        "def predict_ner(text):\n",
        "    \"\"\"Predict NER tags using space tokenization\"\"\"\n",
        "    words = space_tokenizer(text)\n",
        "    input_ids = torch.tensor([[i for i in range(len(words))]]).to(device)\n",
        "    attention_mask = torch.tensor([[1]*len(words)]).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    predictions = torch.argmax(outputs.logits, dim=-1)[0].tolist()\n",
        "    return words, predictions\n",
        "\n",
        "def visualize_predictions(text):\n",
        "    \"\"\"Color-coded visualization of predictions\"\"\"\n",
        "    words, preds = predict_ner(text)\n",
        "    colors = {\n",
        "        \"Product\": \"\\033[91m\",  # Red\n",
        "        \"PRICE\": \"\\033[92m\",    # Green\n",
        "        \"LOC\": \"\\033[94m\",      # Blue\n",
        "        \"CONTACT\": \"\\033[93m\",  # Yellow\n",
        "    }\n",
        "    reset_color = \"\\033[0m\"\n",
        "\n",
        "    print(\"\\nPrediction Visualization:\")\n",
        "    for word, pred in zip(words, preds):\n",
        "        label = label_list[pred]\n",
        "        if label == \"O\":\n",
        "            print(word, end=\" \")\n",
        "        else:\n",
        "            ent_type = label.split(\"-\")[-1]\n",
        "            color = colors.get(ent_type, \"\")\n",
        "            print(f\"{color}{word}{reset_color}\", end=\" \")\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_tazL7m2Ka3"
      },
      "source": [
        "6. Evaluation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "wxVr5LVE2LWb"
      },
      "outputs": [],
      "source": [
        "def analyze_errors(text, true_labels):\n",
        "    \"\"\"Compare predictions with ground truth\"\"\"\n",
        "    words, preds = predict_ner(text)\n",
        "    true_labels = true_labels.split()\n",
        "\n",
        "    print(\"\\nError Analysis:\")\n",
        "    print(\"{:20} {:15} {:15}\".format(\"Word\", \"True\", \"Predicted\"))\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    errors = []\n",
        "    for word, true, pred in zip(words, true_labels, preds):\n",
        "        pred_label = label_list[pred]\n",
        "        if true != pred_label:\n",
        "            errors.append((word, true, pred_label))\n",
        "        print(\"{:20} {:15} {:15}\".format(word, true, pred_label))\n",
        "\n",
        "    print(\"\\nSummary:\")\n",
        "    print(f\"Total words: {len(words)}\")\n",
        "    print(f\"Errors: {len(errors)}\")\n",
        "    print(f\"Accuracy: {(len(words)-len(errors))/len(words):.2%}\")\n",
        "\n",
        "    return errors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6jgvot92OXf"
      },
      "source": [
        "7. Test Cases Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "I878NeCy2P9Q"
      },
      "outputs": [],
      "source": [
        "test_cases = [\n",
        "    {\n",
        "        \"text\": \"BARDEFU 2 IN 1 Multipurpose juicer áŠ³áˆŠá‰² á‹¨áŒáˆµ áˆ˜ááŒ« á‹‹áŒ‹ 6800 á‰¥áˆ­\",\n",
        "        \"true_labels\": \"B-Product I-Product I-Product I-Product I-Product I-Product O B-Product I-Product O B-PRICE I-PRICE\"\n",
        "    },\n",
        "    {\n",
        "        \"text\": \"8000Watt áˆáˆ‹áŒ®á‰¹ áŒ áŠ•áŠ«áˆ« á‹¨áˆ†áŠ‘ áˆˆá‰¤á‰µ á‹‹áŒ‹ 6800 á‰¥áˆ­\",\n",
        "        \"true_labels\": \"B-Product I-Product I-Product O O O B-PRICE I-PRICE I-PRICE\"\n",
        "    },\n",
        "    {\n",
        "        \"text\": \"áŠ á‹µáˆ«áˆ» á‰1 áˆ˜áŒˆáŠ“áŠ› á‰³áˆœ áŒ‹áˆµ áˆ…áŠ•áƒ áŒŽáŠ• áˆµáˆª áŠ¤áˆ áˆ²á‰² áˆžáˆ 0909522840\",\n",
        "        \"true_labels\": \"B-LOC I-LOC I-LOC I-LOC I-LOC I-LOC O I-LOC I-LOC I-LOC B-CONTACT\"\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XysRmeUd2a7n"
      },
      "source": [
        "8. Test Execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bg_rcYNF2Wme",
        "outputId": "7f1d1e2e-25e5-4848-9eea-ddae5cc3669a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "TEST CASE 1: BARDEFU 2 IN 1 Multipurpose juicer áŠ³áˆŠá‰² á‹¨áŒáˆµ áˆ˜ááŒ« á‹‹áŒ‹ 6800 á‰¥áˆ­\n",
            "==================================================\n",
            "\n",
            "Prediction Visualization:\n",
            "\u001b[93mBARDEFU\u001b[0m \u001b[93m2\u001b[0m \u001b[93mIN\u001b[0m \u001b[93m1\u001b[0m \u001b[93mMultipurpose\u001b[0m \u001b[93mjuicer\u001b[0m \u001b[93máŠ³áˆŠá‰²\u001b[0m \u001b[93má‹¨áŒáˆµ\u001b[0m \u001b[93máˆ˜ááŒ«\u001b[0m \u001b[93má‹‹áŒ‹\u001b[0m \u001b[93m6800\u001b[0m \u001b[93má‰¥áˆ­\u001b[0m \n",
            "\n",
            "\n",
            "Error Analysis:\n",
            "Word                 True            Predicted      \n",
            "--------------------------------------------------\n",
            "BARDEFU              B-Product       I-CONTACT      \n",
            "2                    I-Product       I-CONTACT      \n",
            "IN                   I-Product       I-CONTACT      \n",
            "1                    I-Product       I-CONTACT      \n",
            "Multipurpose         I-Product       I-CONTACT      \n",
            "juicer               I-Product       I-CONTACT      \n",
            "áŠ³áˆŠá‰²                  O               I-CONTACT      \n",
            "á‹¨áŒáˆµ                  B-Product       I-CONTACT      \n",
            "áˆ˜ááŒ«                  I-Product       I-CONTACT      \n",
            "á‹‹áŒ‹                   O               I-CONTACT      \n",
            "6800                 B-PRICE         I-CONTACT      \n",
            "á‰¥áˆ­                   I-PRICE         I-CONTACT      \n",
            "\n",
            "Summary:\n",
            "Total words: 12\n",
            "Errors: 12\n",
            "Accuracy: 0.00%\n",
            "\n",
            "First error: 'BARDEFU' (True: B-Product, Pred: I-CONTACT)\n",
            "\n",
            "Generating SHAP-style explanation...\n",
            "Feature importance by position:\n",
            "Word            Position   Importance\n",
            "----------------------------------------\n",
            "BARDEFU                  0 0.00\n",
            "2                        1 0.00\n",
            "IN                       2 0.00\n",
            "1                        3 0.00\n",
            "Multipurpose             4 0.00\n",
            "juicer                   5 0.00\n",
            "áŠ³áˆŠá‰²                      6 0.00\n",
            "á‹¨áŒáˆµ                      7 0.00\n",
            "áˆ˜ááŒ«                      8 0.00\n",
            "á‹‹áŒ‹                       9 0.00\n",
            "6800                    10 0.00\n",
            "á‰¥áˆ­                      11 0.00\n",
            "\n",
            "Key:\n",
            "Importance = How much prediction changes when word is masked\n",
            "\n",
            "Generating LIME-style explanation for B-Product...\n",
            "\n",
            "Top influential words:\n",
            "Word            Position   Influence\n",
            "----------------------------------------\n",
            "BARDEFU                  0 0.00\n",
            "2                        1 0.00\n",
            "IN                       2 0.00\n",
            "1                        3 0.00\n",
            "Multipurpose             4 0.00\n",
            "\n",
            "Generating SHAP-style explanation...\n",
            "Feature importance by position:\n",
            "Word            Position   Importance\n",
            "----------------------------------------\n",
            "BARDEFU                  0 0.00\n",
            "2                        1 0.00\n",
            "IN                       2 0.00\n",
            "1                        3 0.00\n",
            "Multipurpose             4 0.00\n",
            "juicer                   5 0.00\n",
            "áŠ³áˆŠá‰²                      6 0.00\n",
            "á‹¨áŒáˆµ                      7 0.00\n",
            "áˆ˜ááŒ«                      8 0.00\n",
            "á‹‹áŒ‹                       9 0.00\n",
            "6800                    10 0.00\n",
            "á‰¥áˆ­                      11 0.00\n",
            "\n",
            "Key:\n",
            "Importance = How much prediction changes when word is masked\n",
            "\n",
            "Generating LIME-style explanation for B-Product...\n",
            "\n",
            "Top influential words:\n",
            "Word            Position   Influence\n",
            "----------------------------------------\n",
            "BARDEFU                  0 0.00\n",
            "2                        1 0.00\n",
            "IN                       2 0.00\n",
            "1                        3 0.00\n",
            "Multipurpose             4 0.00\n",
            "\n",
            "==================================================\n",
            "COMPLETED TEST CASE 1\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST CASE 2: 8000Watt áˆáˆ‹áŒ®á‰¹ áŒ áŠ•áŠ«áˆ« á‹¨áˆ†áŠ‘ áˆˆá‰¤á‰µ á‹‹áŒ‹ 6800 á‰¥áˆ­\n",
            "==================================================\n",
            "\n",
            "Prediction Visualization:\n",
            "\u001b[93m8000Watt\u001b[0m \u001b[93máˆáˆ‹áŒ®á‰¹\u001b[0m \u001b[92máŒ áŠ•áŠ«áˆ«\u001b[0m \u001b[93má‹¨áˆ†áŠ‘\u001b[0m \u001b[92máˆˆá‰¤á‰µ\u001b[0m \u001b[92má‹‹áŒ‹\u001b[0m \u001b[92m6800\u001b[0m \u001b[92má‰¥áˆ­\u001b[0m \n",
            "\n",
            "\n",
            "Error Analysis:\n",
            "Word                 True            Predicted      \n",
            "--------------------------------------------------\n",
            "8000Watt             B-Product       I-CONTACT      \n",
            "áˆáˆ‹áŒ®á‰¹                 I-Product       I-CONTACT      \n",
            "áŒ áŠ•áŠ«áˆ«                 I-Product       B-PRICE        \n",
            "á‹¨áˆ†áŠ‘                  O               I-CONTACT      \n",
            "áˆˆá‰¤á‰µ                  O               B-PRICE        \n",
            "á‹‹áŒ‹                   O               B-PRICE        \n",
            "6800                 B-PRICE         B-PRICE        \n",
            "á‰¥áˆ­                   I-PRICE         B-PRICE        \n",
            "\n",
            "Summary:\n",
            "Total words: 8\n",
            "Errors: 7\n",
            "Accuracy: 12.50%\n",
            "\n",
            "First error: '8000Watt' (True: B-Product, Pred: I-CONTACT)\n",
            "\n",
            "Generating SHAP-style explanation...\n",
            "Feature importance by position:\n",
            "Word            Position   Importance\n",
            "----------------------------------------\n",
            "8000Watt                 0 0.00\n",
            "áˆáˆ‹áŒ®á‰¹                     1 0.00\n",
            "áŒ áŠ•áŠ«áˆ«                     2 0.00\n",
            "á‹¨áˆ†áŠ‘                      3 0.00\n",
            "áˆˆá‰¤á‰µ                      4 0.00\n",
            "á‹‹áŒ‹                       5 0.00\n",
            "6800                     6 0.00\n",
            "á‰¥áˆ­                       7 0.00\n",
            "\n",
            "Key:\n",
            "Importance = How much prediction changes when word is masked\n",
            "\n",
            "Generating LIME-style explanation for B-Product...\n",
            "\n",
            "Top influential words:\n",
            "Word            Position   Influence\n",
            "----------------------------------------\n",
            "8000Watt                 0 0.00\n",
            "áˆáˆ‹áŒ®á‰¹                     1 0.00\n",
            "áŒ áŠ•áŠ«áˆ«                     2 0.00\n",
            "á‹¨áˆ†áŠ‘                      3 0.00\n",
            "áˆˆá‰¤á‰µ                      4 0.00\n",
            "\n",
            "Generating SHAP-style explanation...\n",
            "Feature importance by position:\n",
            "Word            Position   Importance\n",
            "----------------------------------------\n",
            "8000Watt                 0 0.00\n",
            "áˆáˆ‹áŒ®á‰¹                     1 0.00\n",
            "áŒ áŠ•áŠ«áˆ«                     2 0.00\n",
            "á‹¨áˆ†áŠ‘                      3 0.00\n",
            "áˆˆá‰¤á‰µ                      4 0.00\n",
            "á‹‹áŒ‹                       5 0.00\n",
            "6800                     6 0.00\n",
            "á‰¥áˆ­                       7 0.00\n",
            "\n",
            "Key:\n",
            "Importance = How much prediction changes when word is masked\n",
            "\n",
            "Generating LIME-style explanation for B-Product...\n",
            "\n",
            "Top influential words:\n",
            "Word            Position   Influence\n",
            "----------------------------------------\n",
            "8000Watt                 0 0.00\n",
            "áˆáˆ‹áŒ®á‰¹                     1 0.00\n",
            "áŒ áŠ•áŠ«áˆ«                     2 0.00\n",
            "á‹¨áˆ†áŠ‘                      3 0.00\n",
            "áˆˆá‰¤á‰µ                      4 0.00\n",
            "\n",
            "==================================================\n",
            "COMPLETED TEST CASE 2\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST CASE 3: áŠ á‹µáˆ«áˆ» á‰1 áˆ˜áŒˆáŠ“áŠ› á‰³áˆœ áŒ‹áˆµ áˆ…áŠ•áƒ áŒŽáŠ• áˆµáˆª áŠ¤áˆ áˆ²á‰² áˆžáˆ 0909522840\n",
            "==================================================\n",
            "\n",
            "Prediction Visualization:\n",
            "\u001b[93máŠ á‹µáˆ«áˆ»\u001b[0m \u001b[93má‰1\u001b[0m \u001b[93máˆ˜áŒˆáŠ“áŠ›\u001b[0m \u001b[93má‰³áˆœ\u001b[0m \u001b[93máŒ‹áˆµ\u001b[0m \u001b[93máˆ…áŠ•áƒ\u001b[0m \u001b[93máŒŽáŠ•\u001b[0m \u001b[93máˆµáˆª\u001b[0m \u001b[93máŠ¤áˆ\u001b[0m \u001b[93máˆ²á‰²\u001b[0m \u001b[93máˆžáˆ\u001b[0m \u001b[93m0909522840\u001b[0m \n",
            "\n",
            "\n",
            "Error Analysis:\n",
            "Word                 True            Predicted      \n",
            "--------------------------------------------------\n",
            "áŠ á‹µáˆ«áˆ»                 B-LOC           I-CONTACT      \n",
            "á‰1                   I-LOC           I-CONTACT      \n",
            "áˆ˜áŒˆáŠ“áŠ›                 I-LOC           I-CONTACT      \n",
            "á‰³áˆœ                   I-LOC           I-CONTACT      \n",
            "áŒ‹áˆµ                   I-LOC           I-CONTACT      \n",
            "áˆ…áŠ•áƒ                  I-LOC           I-CONTACT      \n",
            "áŒŽáŠ•                   O               I-CONTACT      \n",
            "áˆµáˆª                   I-LOC           I-CONTACT      \n",
            "áŠ¤áˆ                   I-LOC           I-CONTACT      \n",
            "áˆ²á‰²                   I-LOC           I-CONTACT      \n",
            "áˆžáˆ                   B-CONTACT       I-CONTACT      \n",
            "\n",
            "Summary:\n",
            "Total words: 12\n",
            "Errors: 11\n",
            "Accuracy: 8.33%\n",
            "\n",
            "First error: 'áŠ á‹µáˆ«áˆ»' (True: B-LOC, Pred: I-CONTACT)\n",
            "\n",
            "Generating SHAP-style explanation...\n",
            "Feature importance by position:\n",
            "Word            Position   Importance\n",
            "----------------------------------------\n",
            "áŠ á‹µáˆ«áˆ»                     0 0.00\n",
            "á‰1                       1 0.00\n",
            "áˆ˜áŒˆáŠ“áŠ›                     2 0.00\n",
            "á‰³áˆœ                       3 0.00\n",
            "áŒ‹áˆµ                       4 0.00\n",
            "áˆ…áŠ•áƒ                      5 0.00\n",
            "áŒŽáŠ•                       6 0.00\n",
            "áˆµáˆª                       7 0.00\n",
            "áŠ¤áˆ                       8 0.00\n",
            "áˆ²á‰²                       9 0.00\n",
            "áˆžáˆ                      10 0.00\n",
            "0909522840              11 0.00\n",
            "\n",
            "Key:\n",
            "Importance = How much prediction changes when word is masked\n",
            "\n",
            "Generating LIME-style explanation for B-LOC...\n",
            "\n",
            "Top influential words:\n",
            "Word            Position   Influence\n",
            "----------------------------------------\n",
            "áŠ á‹µáˆ«áˆ»                     0 0.00\n",
            "á‰1                       1 0.00\n",
            "áˆ˜áŒˆáŠ“áŠ›                     2 0.00\n",
            "á‰³áˆœ                       3 0.00\n",
            "áŒ‹áˆµ                       4 0.00\n",
            "\n",
            "Generating SHAP-style explanation...\n",
            "Feature importance by position:\n",
            "Word            Position   Importance\n",
            "----------------------------------------\n",
            "áŠ á‹µáˆ«áˆ»                     0 0.00\n",
            "á‰1                       1 0.00\n",
            "áˆ˜áŒˆáŠ“áŠ›                     2 0.00\n",
            "á‰³áˆœ                       3 0.00\n",
            "áŒ‹áˆµ                       4 0.00\n",
            "áˆ…áŠ•áƒ                      5 0.00\n",
            "áŒŽáŠ•                       6 0.00\n",
            "áˆµáˆª                       7 0.00\n",
            "áŠ¤áˆ                       8 0.00\n",
            "áˆ²á‰²                       9 0.00\n",
            "áˆžáˆ                      10 0.00\n",
            "0909522840              11 0.00\n",
            "\n",
            "Key:\n",
            "Importance = How much prediction changes when word is masked\n",
            "\n",
            "Generating LIME-style explanation for B-Product...\n",
            "\n",
            "Top influential words:\n",
            "Word            Position   Influence\n",
            "----------------------------------------\n",
            "áŠ á‹µáˆ«áˆ»                     0 0.00\n",
            "á‰1                       1 0.00\n",
            "áˆ˜áŒˆáŠ“áŠ›                     2 0.00\n",
            "á‰³áˆœ                       3 0.00\n",
            "áŒ‹áˆµ                       4 0.00\n",
            "\n",
            "==================================================\n",
            "COMPLETED TEST CASE 3\n",
            "==================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i, test_case in enumerate(test_cases, 1):\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"TEST CASE {i}: {test_case['text']}\")\n",
        "    print(f\"{'='*50}\")\n",
        "\n",
        "    # 1. Basic prediction\n",
        "    visualize_predictions(test_case['text'])\n",
        "\n",
        "    # 2. Error analysis\n",
        "    if 'true_labels' in test_case:\n",
        "        errors = analyze_errors(test_case['text'], test_case['true_labels'])\n",
        "\n",
        "        if errors:\n",
        "            error_word, true_label, pred_label = errors[0]\n",
        "            print(f\"\\nFirst error: '{error_word}' (True: {true_label}, Pred: {pred_label})\")\n",
        "\n",
        "            # Add SHAP and LIME explanations for errors\n",
        "            try:\n",
        "                # SHAP explanation\n",
        "                shap_explanation(test_case['text'], model, tokenizer)\n",
        "\n",
        "                # LIME explanation for the true label\n",
        "                true_label_idx = label_list.index(true_label)\n",
        "                lime_explanation(test_case['text'], model, tokenizer, true_label_idx)\n",
        "            except Exception as e:\n",
        "                print(f\"Interpretability failed: {str(e)}\")\n",
        "\n",
        "    # 3. General explanations even without errors\n",
        "    try:\n",
        "        # SHAP explanation for Product entities\n",
        "        shap_explanation(test_case['text'], model, tokenizer)\n",
        "\n",
        "        # LIME explanation for first entity type\n",
        "        lime_explanation(test_case['text'], model, tokenizer, 1)  # 1 = B-Product\n",
        "    except Exception as e:\n",
        "        print(f\"General interpretability failed: {str(e)}\")\n",
        "\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"COMPLETED TEST CASE {i}\")\n",
        "    print(f\"{'='*50}\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0023e524c155470b9072937262552d64": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02358d24f38742ca9a8bd1b4690fde99": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "122f8d8c929147c290e26b8e127f6088": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "139a267d68254d6da852f09ed419bfe6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1a345eb23fd44f1fbaf05def87e7fa7e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f251f078feb4a718666df2f5446431d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "24838e09e821480d8bd2eb8f2ef9bdd0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "285924c9d8ce4f7eb8087ab58f314209": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5314529e7d164e13a5ebd34d207713b0",
              "IPY_MODEL_4a435505f1be434b81630dc598873ef9",
              "IPY_MODEL_dab32f4732ff4f8e9d636dbe2bb5a9b9"
            ],
            "layout": "IPY_MODEL_c915d0e0cb364bce8b142369e674ad0c"
          }
        },
        "2bb61384fb3c430c82448ae9d9ecbed0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "489987fd81f840899fef881fe41ef791": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_935ec902e2fe438aa3ba88a5ad3ae93f",
              "IPY_MODEL_8bff119429cd44aa9cf2a66927389865",
              "IPY_MODEL_c9b8f030cf4e49cba5f6e13436836e28"
            ],
            "layout": "IPY_MODEL_9ed405e357054df68ede0a5ab0644bbd"
          }
        },
        "4a435505f1be434b81630dc598873ef9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0023e524c155470b9072937262552d64",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1f251f078feb4a718666df2f5446431d",
            "value": 2
          }
        },
        "5314529e7d164e13a5ebd34d207713b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bf2726c11064379a50fe01eaafc2161",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_139a267d68254d6da852f09ed419bfe6",
            "value": "Map:â€‡100%"
          }
        },
        "53ecf12ff9db40dd89cabf2fcf7ecdc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02358d24f38742ca9a8bd1b4690fde99",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_abfc0c68c35546a58e48c062019067c8",
            "value": "Map:â€‡100%"
          }
        },
        "5d8a2212d9ec4a3cadbbc6ea90fb29a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e9efa3af71a4355ab80b0c2564e566d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62cfc3ccfe2043fcaeee888df503ffdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a345eb23fd44f1fbaf05def87e7fa7e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5e9efa3af71a4355ab80b0c2564e566d",
            "value": "â€‡2/2â€‡[00:00&lt;00:00,â€‡39.42â€‡examples/s]"
          }
        },
        "6925c5f683a342e3baadec99c1be6976": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "71085a3c414a4aaa8eabd0cc1508eefb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aaf5d1f1327d431c88c4ca9667711d4c",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d427400442b44559854ad067526792c2",
            "value": 2
          }
        },
        "7bf2726c11064379a50fe01eaafc2161": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bff119429cd44aa9cf2a66927389865": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24838e09e821480d8bd2eb8f2ef9bdd0",
            "max": 6,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6925c5f683a342e3baadec99c1be6976",
            "value": 6
          }
        },
        "935ec902e2fe438aa3ba88a5ad3ae93f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d8a2212d9ec4a3cadbbc6ea90fb29a4",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_2bb61384fb3c430c82448ae9d9ecbed0",
            "value": "Map:â€‡100%"
          }
        },
        "9ed405e357054df68ede0a5ab0644bbd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a87c1e7249bb44418392a8176942750a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aaf5d1f1327d431c88c4ca9667711d4c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abfc0c68c35546a58e48c062019067c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b706fe19734841799dcbc7fb50f46981": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c20edfca4e3147078190ffdbde5358fc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c915d0e0cb364bce8b142369e674ad0c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9b8f030cf4e49cba5f6e13436836e28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a87c1e7249bb44418392a8176942750a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f9eeac8cb33c4315bc07aa4b9913bae1",
            "value": "â€‡6/6â€‡[00:00&lt;00:00,â€‡103.44â€‡examples/s]"
          }
        },
        "d427400442b44559854ad067526792c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dab32f4732ff4f8e9d636dbe2bb5a9b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b706fe19734841799dcbc7fb50f46981",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_122f8d8c929147c290e26b8e127f6088",
            "value": "â€‡2/2â€‡[00:00&lt;00:00,â€‡37.88â€‡examples/s]"
          }
        },
        "f9eeac8cb33c4315bc07aa4b9913bae1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fffd872fd6f746fdb7e1c880d1c1750d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_53ecf12ff9db40dd89cabf2fcf7ecdc4",
              "IPY_MODEL_71085a3c414a4aaa8eabd0cc1508eefb",
              "IPY_MODEL_62cfc3ccfe2043fcaeee888df503ffdf"
            ],
            "layout": "IPY_MODEL_c20edfca4e3147078190ffdbde5358fc"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}